{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa58c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smart\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import nltk                                      # Natural Language processing. Para el análisis lintuistico de documentos. \n",
    "from nltk.stem.lancaster import LancasterStemmer # Permite transformar palabras para que sea mas entendible (letras de mas o errores de tipeo, ect).\n",
    "stemmer = LancasterStemmer ()\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tflearn                                   # Para la implementación de redes neuronales multicapa\n",
    "import json\n",
    "import random\n",
    "import pickle                                    # Permite guardar el modelo y no cargarlo cada vez que se ejecute el programa\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62bc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"estandar.json\", encoding='utf-8') as archivo:\n",
    "    datos = json.load(archivo)\n",
    "    \n",
    "# print(datos) #muestra de datos y prueba de carga correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed30913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "# El 'try' permite almacenar los parametros del modelo para proximas ejecuciones. Se debe dejar comentado para las pruebas iniciales del sistema!!\n",
    "\n",
    "########### Inicio comentado de almacenamiento ################################\n",
    "# try: \n",
    "#     with open(\"variables.pickle\",\"rb\") as archivoPickle:\n",
    "#         palabras, tags, entrenamiento, salida = pickle.load(archivoPickle)\n",
    "\n",
    "# except:\n",
    "###############################################################################\n",
    "\n",
    "palabras=[]\n",
    "tags=[]\n",
    "auxX=[]  # palabras que se asignaran a la lista \"palabras\"\n",
    "auxY=[]\n",
    "\n",
    "for contenido in datos[\"cuentas\"]:\n",
    "    for patrones in contenido[\"patrones\"]:\n",
    "        auxPalabra = nltk.word_tokenize(patrones) # Toma una frase y la separa en palabras (tokens), para identificar los patrones a parametrizar\n",
    "        palabras.extend(auxPalabra)               # Almacena todas las palabras tokenizadas \n",
    "        auxX.append(auxPalabra)                   \n",
    "        auxY.append(contenido[\"tag\"])\n",
    "\n",
    "        if contenido[\"tag\"] not in tags:          # Agrega un tag si no lo encuentra\n",
    "            tags.append(contenido[\"tag\"])\n",
    "\n",
    "palabras = [stemmer.stem(w.lower()) for w in palabras if w != \"\\n\"]   #stemmer permite identificar palabras equivalentes (por ejemplo: Banco = Bco. = banco)\n",
    "palabras = sorted(list(set(palabras)))            # Se define la palabra\n",
    "tags = sorted(tags)                               # Se define el tag\n",
    "\n",
    "entrenamiento = []\n",
    "salida = []\n",
    "salidaVacia = [0 for _ in range(len(tags))]\n",
    "\n",
    "for x, documento in enumerate(auxX):              # en X se guardara el indice de la palabra\n",
    "    cubeta=[]                                     #Lista auxiliar para almacenar las palabras \n",
    "    auxPalabra = [stemmer.stem(w.lower()) for w in documento]\n",
    "    for w in palabras:\n",
    "        if w in auxPalabra:\n",
    "            cubeta.append(1)\n",
    "        else:\n",
    "            cubeta.append(0)\n",
    "\n",
    "    filaSalida = salidaVacia[:]\n",
    "    filaSalida[tags.index(auxY[x])] = 1            #en la posicion del indice del tag, obtenemos el indice del auxiliar\n",
    "    entrenamiento.append(cubeta)\n",
    "    salida.append(filaSalida)\n",
    "\n",
    "entrenamiento = numpy.array(entrenamiento)\n",
    "salida = numpy.array(salida)\n",
    "\n",
    "# ########### Inicio comentado de almacenamiento ##################################\n",
    "\n",
    "#     with open(\"variables.pickle\",\"wb\") as archivoPickle:\n",
    "#             pickle.dump((palabras, tags, entrenamiento, salida), archivoPickle)\n",
    "            \n",
    "# #################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7131515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 18799  | total loss: \u001b[1m\u001b[32m0.57299\u001b[0m\u001b[0m | time: 0.268s\n",
      "| Adam | epoch: 400 | loss: 0.57299 - acc: 0.9109 -- iter: 1840/1856\n",
      "Training Step: 18800  | total loss: \u001b[1m\u001b[32m0.53605\u001b[0m\u001b[0m | time: 0.268s\n",
      "| Adam | epoch: 400 | loss: 0.53605 - acc: 0.9098 -- iter: 1856/1856\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\smart\\Downloads\\8_Chat\\modelo.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:C:\\Users\\smart\\Downloads\\8_Chat\\modelo.tflearn.data-00000-of-00001\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:C:\\Users\\smart\\Downloads\\8_Chat\\modelo.tflearn.index\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:C:\\Users\\smart\\Downloads\\8_Chat\\modelo.tflearn.meta\n",
      "INFO:tensorflow:300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "\n",
    "    ### Creación red neuronal inicial de 4 redes, con 10 neuronas c/u\n",
    "\n",
    "red = tflearn.input_data(shape=[None,len(entrenamiento[0])]) # Datos de entrada a entrenar\n",
    "red = tflearn.fully_connected(red,10)                        # Se crean capas conectadas con 10 unidades/neuronas\n",
    "red = tflearn.fully_connected(red,10)\n",
    "#red = tflearn.fully_connected(red,10)\n",
    "red = tflearn.fully_connected(red,len(salida[0]),activation=\"softmax\") # función de activación de las capas ocultas\n",
    "red = tflearn.regression(red, optimizer='adam', loss='categorical_crossentropy') #permite obtener la probabilidad de que tan eficaz es la clasificacion de los tag\n",
    "\n",
    "modelo = tflearn.DNN(red)\n",
    "#try:\n",
    "#    modelo.load(\"modelo.tflearn\")\n",
    "#except:\n",
    "\n",
    "historial = modelo.fit(entrenamiento,salida,n_epoch=400,batch_size=40,show_metric=True) #Entrenamiento para el proceso de modelado\n",
    "\n",
    "modelo.save(\"modelo.tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4ca7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "def agregarPDF(cuentas, respuesta):\n",
    "\n",
    "    pdf = FPDF(orientation = 'L', unit = 'mm', format='A4') \n",
    "    pdf.add_page()\n",
    "\n",
    "    pdf.add_font('DejaVu', '', 'DejaVuSansCondensed.ttf', uni=True)\n",
    "    pdf.set_font('DejaVu', '', 11)\n",
    "\n",
    "    print(respuesta[0])\n",
    "    # TEXTO\n",
    "    #pdf.set_font('Arial', '', 10)\n",
    "\n",
    "    # titulo\n",
    "    pdf.cell(w = 0, h = 15, txt = 'Balance General', border = 1, ln=1, align = 'C', fill = 0)\n",
    "    # encabezado\n",
    "\n",
    "\n",
    "    pdf.cell(w = 30, h = 15, txt = 'Cuenta', border = 1, align = 'C', fill = 0)\n",
    "    pdf.cell(w = 30, h = 15, txt = 'Activo', border = 1, align = 'C', fill = 0)\n",
    "    pdf.cell(w = 30, h = 15, txt = 'Pasivo', border = 1, align = 'C', fill = 0)\n",
    "    pdf.cell(w = 30, h = 15, txt = 'Perdida', border = 1, align = 'C', fill = 0)\n",
    "    pdf.cell(w = 30, h = 15, txt = 'Ganancia', border = 1, align = 'C', fill = 0)\n",
    "    \n",
    "    pdf.multi_cell(w = 0, h = 15, txt = 'Descripcion', border = 1, align = 'C', fill = 0)\n",
    "\n",
    "\n",
    "    #Tag: nombres de las cuentas resultantes de la estandarizacion\n",
    "    #Datos\n",
    "    #print(tag + \"---------------- \" + datos[\"nombre_cliente\"])\n",
    "    cont = 0\n",
    "    for row in cuentas:\n",
    "        #print(row)\n",
    "        #print(respuesta[cont])\n",
    "        if(cont < len(respuesta)):            \n",
    "            char = respuesta[cont]\n",
    "            \n",
    "        cont = cont + 1\n",
    "        perdida = row[\"perdida\"]\n",
    "        #pdf.cell(w = 30, h = 9, txt = char, border = 1, align = 'C', fill = 0)\n",
    "        pdf.cell(w = 30, h = 7, txt = row[\"id_estandar\"], border = 1, align = 'C', fill = 0)\n",
    "        pdf.cell(w = 30, h = 7, txt = row[\"activo\"], border = 1, align = 'C', fill = 0)\n",
    "        pdf.cell(w = 30, h = 7, txt = row[\"pasivo\"], border = 1, align = 'C', fill = 0)\n",
    "        pdf.cell(w = 30, h = 7, txt = row[\"perdida\"], border = 1, align = 'C', fill = 0)\n",
    "        pdf.cell(w = 30, h = 7, txt = row[\"ganancia\"], border = 1, align = 'C', fill = 0)\n",
    "\n",
    "        pdf.multi_cell(w = 0, h = 7, txt = char, border = 1, align = 'C', fill = 0)\n",
    "        \n",
    "    \n",
    "    #pdf.output('hoja.pdf')\n",
    "    pdf.output(\"hoja.pdf\", 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d395e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datos_entrenamiento/balance_puerto_lapiz.csv', newline='') as f:\n",
    "    reader = csv.DictReader(f,delimiter=';')\n",
    "    \n",
    "    cuentas = []\n",
    "    for row in reader: \n",
    "        cuentas.append(row) \n",
    "        #balance_salida.append(row)\n",
    "        #print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4084d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disponible\n",
      "Estandarización completa!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mainBot():\n",
    "    respuesta = []  # Temporal !!!\n",
    "    \n",
    "    #entrada = input(\"Usuario: \")\n",
    "    count = 1   ############### Provisorio\n",
    "    for x in range(len(cuentas) - 5):\n",
    "        #print(\"-------------------\",count,\"-------------------\")       ############### Provisorio\n",
    "        aux = cuentas[x]\n",
    "        indice = aux[\"nombre_cliente\"]\n",
    "        count = count + 1    ############### Provisorio\n",
    "        cubeta = [0 for _ in range(len(palabras))]\n",
    "        entradaProcesada = nltk.word_tokenize(indice)\n",
    "        entradaProcesada = [stemmer.stem(palabra.lower()) for palabra in entradaProcesada]\n",
    "        for palabraIndividual in entradaProcesada:\n",
    "            for i,palabra in enumerate(palabras):\n",
    "                if palabra == palabraIndividual:\n",
    "                    cubeta[i] = 1\n",
    "        resultados = modelo.predict([numpy.array(cubeta)])\n",
    "        resultadosIndices = numpy.argmax(resultados)\n",
    "        tag = tags[resultadosIndices]\n",
    "        respuesta.append(tag)\n",
    "        \n",
    "    agregarPDF(cuentas, respuesta)    \n",
    "    print(\"Estandarización completa!!\")\n",
    "    #agregarPDF(cuentas, respuesta)\n",
    "\n",
    "mainBot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0c488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc311f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eddb731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfeed3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fde41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11640940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f27eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971b451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76034318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee098d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf33062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
