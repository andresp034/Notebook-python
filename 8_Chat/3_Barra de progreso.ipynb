{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc3bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smart\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer #permite transformar palabras para que sea mas entendible (letras de mas o errores de tipeo, ect).\n",
    "stemmer = LancasterStemmer ()\n",
    "import numpy\n",
    "import tensorflow\n",
    "import tflearn\n",
    "import json\n",
    "import random\n",
    "import pickle #permite guardar el modelo y no cargarlo cada vez que se ejecute el programa\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff755c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"estandar.json\", encoding='utf-8') as archivo:\n",
    "    datos = json.load(archivo)\n",
    "    \n",
    "# print(datos) #muestra de datos y prueba de carga correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f4eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "palabras=[]\n",
    "tags=[]\n",
    "auxX=[] #palabras que se asignaran a la lista \"palabras\"\n",
    "auxY=[]\n",
    "\n",
    "for contenido in datos[\"contenido\"]:\n",
    "    for patrones in contenido[\"patrones\"]:\n",
    "        auxPalabra = nltk.word_tokenize(patrones) # Toma una frase y la separa en palabras (tokens), para identificar los patrones a parametrizar\n",
    "        palabras.extend(auxPalabra)               # Almacena todas las palabras tokenizadas \n",
    "        auxX.append(auxPalabra)                   \n",
    "        auxY.append(contenido[\"tag\"])\n",
    "\n",
    "        if contenido[\"tag\"] not in tags:          # Agrega un tag si no lo encuentra\n",
    "            tags.append(contenido[\"tag\"])\n",
    "\n",
    "palabras = [stemmer.stem(w.lower()) for w in palabras if w != \"\\n\"]   \n",
    "palabras = sorted(list(set(palabras)))            # Se define la palabra\n",
    "tags = sorted(tags)                               # Se define el tag\n",
    "\n",
    "entrenamiento = []\n",
    "salida = []\n",
    "salidaVacia = [0 for _ in range(len(tags))]\n",
    "\n",
    "for x, documento in enumerate(auxX):              # en X se guardara el indice de la palabra\n",
    "    cubeta=[]                                     #Lista auxiliar para almacenar las palabras \n",
    "    auxPalabra = [stemmer.stem(w.lower()) for w in documento]\n",
    "    for w in palabras:\n",
    "        if w in auxPalabra:\n",
    "            cubeta.append(1)\n",
    "        else:\n",
    "            cubeta.append(0)\n",
    "\n",
    "    filaSalida = salidaVacia[:]\n",
    "    filaSalida[tags.index(auxY[x])] = 1            #en la posicion del indice del tag, obtenemos el indice del auxiliar\n",
    "    entrenamiento.append(cubeta)\n",
    "    salida.append(filaSalida)\n",
    "\n",
    "entrenamiento = numpy.array(entrenamiento)\n",
    "salida = numpy.array(salida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1df385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "\n",
    "    ### creacion red neuronal\n",
    "\n",
    "#    modelo.load(\"modelo.tflearn\")\n",
    "#except:\n",
    "\n",
    "#modelo.fit(entrenamiento,salida,n_epoch=1000,batch_size=40,show_metric=True) #Entrenamiento para el proceso de modelado\n",
    "#modelo.save(\"modelo.tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df77a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox\n",
    "from tkinter.ttk import Progressbar\n",
    "\n",
    "from time import sleep\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process, current_process\n",
    "\n",
    "class Proceso(tk.Frame):\n",
    "\n",
    "    def __init__(self, master=None):\n",
    "        super().__init__(master)\n",
    "        self.master = master\n",
    "        self.pack()\n",
    "\n",
    "        self.inicializar_gui()\n",
    "\n",
    "    def inicializar_gui(self):\n",
    "        self.progreso = tk.DoubleVar()\n",
    "        self.pbr_tarea = Progressbar(self, length=250, style='black.Horizontal.TProgressbar', variable=self.progreso, maximum=100)\n",
    "        self.pbr_tarea['value'] = 0\n",
    "        self.pbr_tarea.grid(row=0, column=0)\n",
    "\n",
    "        tk.Button(self, text='Iniciar tarea', command=self.iniciar_tarea).grid(row=1, column=0)\n",
    "    \n",
    "    def iniciar_tarea(self):\n",
    "        contador = 0\n",
    "        \n",
    "        red = tflearn.input_data(shape=[None,len(entrenamiento[0])]) # Datos de entrada a entrenar\n",
    "        red = tflearn.fully_connected(red,10)                        # Se crean capas conectadas con 10 unidades/neuronas\n",
    "        red = tflearn.fully_connected(red,10)\n",
    "        red = tflearn.fully_connected(red,len(salida[0]),activation=\"softmax\")\n",
    "        red = tflearn.regression(red) #permite obtener la probabilidad de que tan eficaz es la clasificacion de los tag\n",
    "\n",
    "        modelo = tflearn.DNN(red)\n",
    "    #try:\n",
    "    #    modelo.load(\"modelo.tflearn\")\n",
    "    #except:\n",
    "\n",
    "\n",
    "        #n_epoch = 0\n",
    "        while contador <= 200:\n",
    "            self.progreso.set(contador)\n",
    "            contador += 10\n",
    "            \n",
    "        def  fnc_square():\n",
    "            modelo.fit(entrenamiento,salida,n_epoch=200,batch_size=40,show_metric=True) #Entrenamiento para el proceso de modelado\n",
    "            modelo.save(\"modelo.tflearn\")\n",
    "    \n",
    "        pool = Pool(processes=4)\n",
    "        result = pool.apply_async(fnc_square)\n",
    "        result.get(timeout=1)\n",
    "        pool.map(fnc_square())\n",
    "        \n",
    "        \n",
    "        self.master.update_idletasks()\n",
    "        sleep(1)\n",
    "\n",
    "        messagebox.showinfo('Mensaje', 'La tarea ha terminado')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8cb5db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smart\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\smart\\AppData\\Local\\Temp\\ipykernel_21316\\846348274.py\", line 51, in iniciar_tarea\n",
      "    result.get(timeout=1)\n",
      "  File \"C:\\Users\\smart\\anaconda3\\lib\\multiprocessing\\pool.py\", line 771, in get\n",
      "    raise self._value\n",
      "  File \"C:\\Users\\smart\\anaconda3\\lib\\multiprocessing\\pool.py\", line 537, in _handle_tasks\n",
      "    put(task)\n",
      "  File \"C:\\Users\\smart\\anaconda3\\lib\\multiprocessing\\connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"C:\\Users\\smart\\anaconda3\\lib\\multiprocessing\\reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "AttributeError: Can't pickle local object 'Proceso.iniciar_tarea.<locals>.fnc_square'\n"
     ]
    }
   ],
   "source": [
    "app = tk.Tk()\n",
    "app.title('Proceso')\n",
    "app.geometry('300x300')\n",
    "\n",
    "proceso = Proceso(app)\n",
    "proceso.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2303ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cca129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0ac44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd994eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03a5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf97201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
